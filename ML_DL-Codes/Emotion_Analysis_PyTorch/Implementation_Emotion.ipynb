{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementation_Emotion.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAg-V9kM22sx",
        "outputId": "6ca9bec3-88a3-4908-853a-2d1cddfb6da5"
      },
      "source": [
        "! wget https://worksheets.codalab.org/rest/bundles/0x97c870dd60eb4f0fa53f257978851c60/contents/blob/glove.6B.50d.txt -P data/\n",
        "! wget https://github.com/anmol-sinha-coder/Sentiment_Emotion_Analysis/raw/main/Multi_Emotion_Analyzer/emotion_model.pth\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-12 04:21:42--  https://worksheets.codalab.org/rest/bundles/0x97c870dd60eb4f0fa53f257978851c60/contents/blob/glove.6B.50d.txt\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‚Äòdata/glove.6B.50d.txt‚Äô\n",
            "\n",
            "glove.6B.50d.txt        [                <=> ] 163.41M  5.74MB/s    in 2m 5s   \n",
            "\n",
            "2020-12-12 04:23:50 (1.31 MB/s) - ‚Äòdata/glove.6B.50d.txt‚Äô saved [171350079]\n",
            "\n",
            "--2020-12-12 04:23:50--  https://github.com/anmol-sinha-coder/Sentiment_Emotion_Analysis/raw/main/Multi_Emotion_Analyzer/emotion_model.pth\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/anmol-sinha-coder/Sentiment_Emotion_Analysis/main/Multi_Emotion_Analyzer/emotion_model.pth [following]\n",
            "--2020-12-12 04:23:50--  https://raw.githubusercontent.com/anmol-sinha-coder/Sentiment_Emotion_Analysis/main/Multi_Emotion_Analyzer/emotion_model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80902272 (77M) [application/octet-stream]\n",
            "Saving to: ‚Äòemotion_model.pth‚Äô\n",
            "\n",
            "emotion_model.pth   100%[===================>]  77.15M  95.0MB/s    in 0.8s    \n",
            "\n",
            "2020-12-12 04:23:56 (95.0 MB/s) - ‚Äòemotion_model.pth‚Äô saved [80902272/80902272]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3dh3PviD4YU"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_dueg0KP45"
      },
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map\n",
        "\n",
        "\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index, non_trainable=True):\n",
        "    num_embeddings = len(word_to_index) + 1                   \n",
        "    embedding_dim = word_to_vec_map[\"cucumber\"].shape[0]  #  dimensionality of GloVe word vectors (= 50)\n",
        "\n",
        "    # Initialize the embedding matrix as a numpy array of zeros of shape (num_embeddings, embedding_dim)\n",
        "    weights_matrix = np.zeros((num_embeddings, embedding_dim))\n",
        "\n",
        "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
        "    for word, index in word_to_index.items():\n",
        "        weights_matrix[index, :] = word_to_vec_map[word]\n",
        "\n",
        "    embed = nn.Embedding.from_pretrained(torch.from_numpy(weights_matrix).type(torch.FloatTensor), freeze=non_trainable)\n",
        "\n",
        "    return embed, num_embeddings, embedding_dim\n",
        "\n",
        "\n",
        "\n",
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    \"\"\"\n",
        "    m = X.shape[0]  # number of training examples\n",
        "    \n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape\n",
        "    X_indices = np.zeros((m,max_len))\n",
        "    \n",
        "    for i in range(m):  # loop over training examples\n",
        "        \n",
        "        # Convert the ith sentence in lower case and split into a list of words\n",
        "        sentence_words = X[i].lower().split()\n",
        "        \n",
        "        # Initialize j to 0\n",
        "        j = 0\n",
        "        \n",
        "        # Loop over the words of sentence_words\n",
        "        for w in sentence_words:\n",
        "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "            X_indices[i, j] = word_to_index[w]\n",
        "            # Increment j to j + 1\n",
        "            j = j + 1\n",
        "    \n",
        "    return X_indices\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UDW8vEkMuhy"
      },
      "source": [
        "#X_train, Y_train = read_csv('/content/data/train.csv')\n",
        "#X_test, Y_test = read_csv('/content/data/test.csv')\n",
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/data/glove.6B.50d.txt')\n",
        "embedding, vocab_size, embedding_dim = pretrained_embedding_layer(word_to_vec_map, word_to_index, non_trainable=True)\n",
        "\n",
        "hidden_dim=128\n",
        "output_size=5\n",
        "batch_size = 32\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0IXKdvk6FrG"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, embedding, embedding_dim, hidden_dim, vocab_size, output_dim, batch_size):\n",
        "      super(NN, self).__init__()\n",
        "\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.hidden_dim = hidden_dim\n",
        "\n",
        "      self.word_embeddings = embedding\n",
        "\n",
        "      # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "      # with dimensionality hidden_dim.\n",
        "      self.lstm = nn.LSTM(embedding_dim, \n",
        "                          hidden_dim, \n",
        "                          num_layers=2,\n",
        "                          dropout = 0.5,\n",
        "                          batch_first = True)\n",
        "\n",
        "      # The linear layer that maps from hidden state space to output space\n",
        "      self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "      \n",
        "      #sentence = sentence.type(torch.LongTensor)\n",
        "      #print ('Shape of sentence is:', sentence.shape)\n",
        "\n",
        "      sentence = sentence.to(device)\n",
        "\n",
        "      embeds = self.word_embeddings(sentence)\n",
        "      #print ('Embedding layer output shape', embeds.shape)\n",
        "\n",
        "      # initializing the hidden state to 0\n",
        "      #hidden=None\n",
        "      \n",
        "      h0 = torch.zeros(2, sentence.size(0), hidden_dim).requires_grad_().to(device)\n",
        "      c0 = torch.zeros(2, sentence.size(0), hidden_dim).requires_grad_().to(device)\n",
        "      \n",
        "      lstm_out, h = self.lstm(embeds, (h0, c0))\n",
        "      # get info from last timestep only\n",
        "      lstm_out = lstm_out[:, -1, :]\n",
        "      #print ('LSTM layer output shape', lstm_out.shape)\n",
        "      #print ('LSTM layer output ', lstm_out)\n",
        "\n",
        "      # Dropout\n",
        "      lstm_out = F.dropout(lstm_out, 0.5)\n",
        "\n",
        "      fc_out = self.fc(lstm_out)\n",
        "      #print ('FC layer output shape', fc_out.shape)\n",
        "      #print ('FC layer output ', fc_out)\n",
        "      \n",
        "      out = fc_out\n",
        "      out = F.softmax(out, dim=1)\n",
        "      #print ('Output layer output shape', out.shape)\n",
        "      #print ('Output layer output ', out)\n",
        "      return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RmTs10r6m5o",
        "outputId": "3514622a-c5fa-43c3-b140-58542f32b247"
      },
      "source": [
        "model = NN(embedding, embedding_dim, hidden_dim, vocab_size, output_size, batch_size)\n",
        "model.load_state_dict(torch.load('emotion_model.pth', map_location=device))\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (word_embeddings): Embedding(400001, 50)\n",
              "  (lstm): LSTM(50, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-IWGiFSA2Fs"
      },
      "source": [
        "def predict(input_text, print_sentence=True):\n",
        "  labels_dict = {\n",
        "\t\t0 : \"‚ù§Ô∏è Loving\",\n",
        "\t\t1 : \"‚öΩÔ∏è Playful/Excited\",\n",
        "\t\t2 : \"üòÑ Happy\",\n",
        "\t\t3 : \"üòû Annoyed/Sad\",\n",
        "\t\t4 : \"üçΩ Foodie\",\n",
        "\t}\n",
        "  \n",
        "  # Convert the input to the model\n",
        "  x_test = np.array([input_text])\n",
        "  maxLen = len(max(np.asarray([input_text]), key=len).split())\n",
        "  X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "  sentences = torch.tensor(X_test_indices).type(torch.LongTensor)\n",
        "  sentences\n",
        "  model.forward(sentences)\n",
        "  # Get the class label\n",
        "  ps = model(sentences)\n",
        "\n",
        "  top_p, top_class = ps.topk(1, dim=1)\n",
        "  label = int(top_class[0][0])\n",
        "\n",
        "  if print_sentence:\n",
        "    print(\"\\nInput Text: \\t\"+ input_text +'\\nEmotion: \\t'+  labels_dict[label])\n",
        "\n",
        "  return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNG0PHKEQbtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709047ca-ce77-4446-939e-586e1769810f"
      },
      "source": [
        "predict(\"This is the best day of my life\")\n",
        "predict(\"What the hell are you doing ?\")\n",
        "predict(\"Vishwanathan Anand won in chess !\")\n",
        "predict(\"She really likes you now\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Text: \tThis is the best day of my life\n",
            "Emotion: \t‚öΩÔ∏è Playful/Excited\n",
            "\n",
            "Input Text: \tWhat the hell are you doing ?\n",
            "Emotion: \tüòû Annoyed/Sad\n",
            "\n",
            "Input Text: \tVishwanathan Anand won in chess !\n",
            "Emotion: \t‚öΩÔ∏è Playful/Excited\n",
            "\n",
            "Input Text: \tShe really likes you now\n",
            "Emotion: \t‚ù§Ô∏è Loving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCMsBE3GRM6N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}