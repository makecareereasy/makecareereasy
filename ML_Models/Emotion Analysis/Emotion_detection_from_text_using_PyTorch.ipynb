{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion detection from text using PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmol-sinha-coder/Sentiment_Emotion_Analysis/blob/main/Multi_Emotion_Analyzer/Emotion_detection_from_text_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rufFNufqDmUO"
      },
      "source": [
        "# Emotion detection from text using PyTorch and Federated Learning\n",
        "\n",
        "For this project, we are going to implement an NLP task of creating a model to detect the emotion from text. We will develop this using the PyTorch library and the Federated Learning framework for decentralized training. \n",
        "\n",
        "We will create an emotion detection for the following 5 emotions:\n",
        "\n",
        "| Emotion | Emoji   | Label   |\n",
        "|------|------|------|\n",
        "|Loving| ‚ù§Ô∏è| 0|\n",
        "|Playful| ‚öΩÔ∏è| 1|\n",
        "|Happy| üòÑ| 2|\n",
        "|Annoyed| üòû| 3|\n",
        "|Foodie| üçΩ| 4|\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We will work with a dataset (X, Y) where we have:\n",
        "*   X contains 132 sentences\n",
        "*   Y contains a label between [0, 4] corresponding to the five emotions.\n",
        "\n",
        "For example:\n",
        "\n",
        "| Sentence | Emotion   |\n",
        "|----------|-----------|\n",
        "|food is life|  üçΩ Foodie|\n",
        "|I love you mum|  ‚ù§Ô∏è Loving|\n",
        "|Stop saying bullshit|  üòû Annoyed|\n",
        "|congratulations on your acceptance|  üòÑ Happy|\n",
        "|The assignment is too long|    üòû Annoyed|\n",
        "|I want to go play| ‚öΩÔ∏è Playful|\n",
        "|she did not answer my text| üòû Annoyed|\n",
        "|Your stupidity has no limit| üòû Annoyed|\n",
        "|how many points did he score|  ‚öΩÔ∏è Playful|\n",
        "|my algorithm performs poorly| üòû Annoyed|\n",
        "|I got approved|  üòÑ Happy|\n",
        "\n",
        "## The Model\n",
        "We will build an LSTM model that takes as input word sequences that will take word ordering into account. We will use 50-dimensional [GloVe](https://nlp.stanford.edu/projects/glove/) pre-trained word embeddings to represent words. We will then feed those as an input into an LSTM that will predict the most appropiate emotion for the text. \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1s-KYhU5JWF-jvAlZ2MIKKugxLLDdhpQP)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwaKRXyaoyNS",
        "outputId": "4fee00a7-c51b-485a-d5b5-f0a1ba5e9afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/anmol-sinha-coder/Sentiment_Emotion_Analysis/\n",
        "! mkdir data/\n",
        "! cp -r Sentiment_Emotion_Analysis/Multi_Emotion_Analyzer/datasets/* data/\n",
        "! wget https://worksheets.codalab.org/rest/bundles/0x97c870dd60eb4f0fa53f257978851c60/contents/blob/glove.6B.50d.txt -P data/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Sentiment_Emotion_Analysis'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 98579 (delta 22), reused 51 (delta 4), pack-reused 98497\u001b[K\n",
            "Receiving objects: 100% (98579/98579), 99.57 MiB | 21.64 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "Checking out files: 100% (100057/100057), done.\n",
            "--2020-11-13 16:04:32--  https://worksheets.codalab.org/rest/bundles/0x97c870dd60eb4f0fa53f257978851c60/contents/blob/glove.6B.50d.txt\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‚Äòdata/glove.6B.50d.txt‚Äô\n",
            "\n",
            "glove.6B.50d.txt        [       <=>          ] 163.41M   133MB/s    in 1.2s    \n",
            "\n",
            "2020-11-13 16:04:34 (133 MB/s) - ‚Äòdata/glove.6B.50d.txt‚Äô saved [171350079]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQn1wO2qr01C"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d04n5XXyf5Cj"
      },
      "source": [
        "# HELPER FUNCTIONS\n",
        "\n",
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y\n",
        "\n",
        "def read_csv(filename):\n",
        "    phrase = []\n",
        "    emoji = []\n",
        "\n",
        "    with open (filename) as csvDataFile:\n",
        "        csvReader = csv.reader(csvDataFile)\n",
        "\n",
        "        for row in csvReader:\n",
        "            phrase.append(row[0])\n",
        "            emoji.append(row[1])\n",
        "\n",
        "    X = np.asarray(phrase)\n",
        "    Y = np.asarray(emoji, dtype=int)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmqjSlwofS_i"
      },
      "source": [
        "X_train, Y_train = read_csv('/content/data/train.csv')\n",
        "X_test, Y_test = read_csv('/content/data/test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt5z5eqVih4i"
      },
      "source": [
        "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
        "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDe5vX3qiYcB"
      },
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/data/glove.6B.50d.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh0iyxn_jDCR"
      },
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]  # number of training examples\n",
        "    \n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape\n",
        "    X_indices = np.zeros((m,max_len))\n",
        "    \n",
        "    for i in range(m):  # loop over training examples\n",
        "        \n",
        "        # Convert the ith sentence in lower case and split into a list of words\n",
        "        sentence_words = X[i].lower().split()\n",
        "        \n",
        "        # Initialize j to 0\n",
        "        j = 0\n",
        "        \n",
        "        # Loop over the words of sentence_words\n",
        "        for w in sentence_words:\n",
        "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "            X_indices[i, j] = word_to_index[w]\n",
        "            # Increment j to j + 1\n",
        "            j = j + 1\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLyIs_aFjdfl",
        "outputId": "0b36533a-a024-4cbf-85aa-1c9e97f4e977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X1 = np.array([\"lol\", \"I love you\", \"this is very yummy\"])\n",
        "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"X1_indices =\", X1_indices)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X1 = ['lol' 'I love you' 'this is very yummy']\n",
            "X1_indices = [[225122.      0.      0.      0.      0.]\n",
            " [185457. 226278. 394475.      0.      0.]\n",
            " [358160. 192973. 377946. 394957.      0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKHhghrWcNn"
      },
      "source": [
        "## Defining the Network using Pretrained Embedding Layer using GloVe Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZDWRfRkWhwB"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, embedding, embedding_dim, hidden_dim, vocab_size, output_dim, batch_size):\n",
        "      super(NN, self).__init__()\n",
        "\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.hidden_dim = hidden_dim\n",
        "\n",
        "      self.word_embeddings = embedding\n",
        "\n",
        "      # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "      # with dimensionality hidden_dim.\n",
        "      self.lstm = nn.LSTM(embedding_dim, \n",
        "                          hidden_dim, \n",
        "                          num_layers=2,\n",
        "                          dropout = 0.5,\n",
        "                          batch_first = True)\n",
        "\n",
        "      # The linear layer that maps from hidden state space to output space\n",
        "      self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "      \n",
        "      #sentence = sentence.type(torch.LongTensor)\n",
        "      #print ('Shape of sentence is:', sentence.shape)\n",
        "\n",
        "      sentence = sentence.to(device)\n",
        "\n",
        "      embeds = self.word_embeddings(sentence)\n",
        "      #print ('Embedding layer output shape', embeds.shape)\n",
        "\n",
        "      # initializing the hidden state to 0\n",
        "      #hidden=None\n",
        "      \n",
        "      h0 = torch.zeros(2, sentence.size(0), hidden_dim).requires_grad_().to(device)\n",
        "      c0 = torch.zeros(2, sentence.size(0), hidden_dim).requires_grad_().to(device)\n",
        "      \n",
        "      lstm_out, h = self.lstm(embeds, (h0, c0))\n",
        "      # get info from last timestep only\n",
        "      lstm_out = lstm_out[:, -1, :]\n",
        "      #print ('LSTM layer output shape', lstm_out.shape)\n",
        "      #print ('LSTM layer output ', lstm_out)\n",
        "\n",
        "      # Dropout\n",
        "      lstm_out = F.dropout(lstm_out, 0.5)\n",
        "\n",
        "      fc_out = self.fc(lstm_out)\n",
        "      #print ('FC layer output shape', fc_out.shape)\n",
        "      #print ('FC layer output ', fc_out)\n",
        "      \n",
        "      out = fc_out\n",
        "      out = F.softmax(out, dim=1)\n",
        "      #print ('Output layer output shape', out.shape)\n",
        "      #print ('Output layer output ', out)\n",
        "      return out\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK1Bty6f5yQ3"
      },
      "source": [
        "## Creating the Glove Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-UcwaXPgZyj"
      },
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index, non_trainable=True):\n",
        "    num_embeddings = len(word_to_index) + 1                   \n",
        "    embedding_dim = word_to_vec_map[\"cucumber\"].shape[0]  #  dimensionality of GloVe word vectors (= 50)\n",
        "\n",
        "    # Initialize the embedding matrix as a numpy array of zeros of shape (num_embeddings, embedding_dim)\n",
        "    weights_matrix = np.zeros((num_embeddings, embedding_dim))\n",
        "\n",
        "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
        "    for word, index in word_to_index.items():\n",
        "        weights_matrix[index, :] = word_to_vec_map[word]\n",
        "\n",
        "    embed = nn.Embedding.from_pretrained(torch.from_numpy(weights_matrix).type(torch.FloatTensor), freeze=non_trainable)\n",
        "\n",
        "    return embed, num_embeddings, embedding_dim\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7urFqpr5ntp"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEkK7S6v8dVk"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer, epochs=10):\n",
        "    \n",
        "    model.to(device)\n",
        "    running_loss = 0\n",
        "    \n",
        "    train_losses, test_losses, accuracies = [], [], []\n",
        "    for e in range(epochs):\n",
        "\n",
        "        running_loss = 0\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        for sentences, labels in trainloader:\n",
        "\n",
        "            sentences, labels = sentences.to(device), labels.to(device)\n",
        "\n",
        "            # 1) erase previous gradients (if they exist)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 2) make a prediction\n",
        "            pred = model.forward(sentences)\n",
        "\n",
        "            # 3) calculate how much we missed\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            # 4) figure out which weights caused us to miss\n",
        "            loss.backward()\n",
        "\n",
        "            # 5) change those weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # 6) log our progress\n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        \n",
        "        else:\n",
        "\n",
        "          model.eval()\n",
        "\n",
        "          test_loss = 0\n",
        "          accuracy = 0\n",
        "          \n",
        "          # Turn off gradients for validation, saves memory and computations\n",
        "          with torch.no_grad():\n",
        "              for sentences, labels in test_loader:\n",
        "                  sentences, labels = sentences.to(device), labels.to(device)\n",
        "                  log_ps = model(sentences)\n",
        "                  test_loss += criterion(log_ps, labels)\n",
        "                  \n",
        "                  ps = torch.exp(log_ps)\n",
        "                  top_p, top_class = ps.topk(1, dim=1)\n",
        "                  equals = top_class == labels.view(*top_class.shape)\n",
        "                  accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                  \n",
        "          train_losses.append(running_loss/len(train_loader))\n",
        "          test_losses.append(test_loss/len(test_loader))\n",
        "          accuracies.append(accuracy / len(test_loader) * 100)\n",
        "          \n",
        "          print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "                \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "                \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
        "        \n",
        "          if accuracy/len(test_loader)>=0.90:\n",
        "            epochs=e+1\n",
        "            break\n",
        "          \n",
        "        \n",
        "    # Plot\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.plot(train_losses, c='b', label='Training loss')\n",
        "    plt.plot(test_losses, c='r', label='Testing loss')\n",
        "    plt.xticks(np.arange(0, epochs))\n",
        "    plt.title('Losses')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.plot(accuracies)\n",
        "    plt.xticks(np.arange(0, epochs))\n",
        "    plt.title('Accuracy')\n",
        "    plt.show()\n",
        "         \n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgb8si4s9Jb9",
        "outputId": "53c9d4e0-cfd1-46ad-d04f-aca71255feb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.utils.data\n",
        "\n",
        "maxLen = len(max(X_train, key=len).split())\n",
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, C = 5)\n",
        "\n",
        "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
        "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
        "\n",
        "embedding, vocab_size, embedding_dim = pretrained_embedding_layer(word_to_vec_map, word_to_index, non_trainable=True)\n",
        "\n",
        "hidden_dim=128\n",
        "output_size=5\n",
        "batch_size = 32\n",
        "\n",
        "#print ('Embedding layer is ', embedding)\n",
        "#print ('Embedding layer weights ', embedding.weight.shape)\n",
        "\n",
        "model = NN(embedding, embedding_dim, hidden_dim, vocab_size, output_size, batch_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim. RMSprop (model.parameters(), lr=0.002, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "epochs = 10000\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train_indices).type(torch.LongTensor), torch.tensor(Y_train).type(torch.LongTensor))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test_indices).type(torch.LongTensor), torch.tensor(Y_test).type(torch.LongTensor))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "train(model, train_loader, criterion, optimizer, epochs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 5001/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5002/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5003/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5004/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5005/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5006/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5007/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5008/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5009/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5010/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5011/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5012/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5013/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5014/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5015/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5016/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5017/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5018/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5019/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5020/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5021/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5022/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5023/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5024/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5025/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5026/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.818\n",
            "Epoch: 5027/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5028/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5029/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5030/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5031/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5032/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5033/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5034/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5035/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5036/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5037/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5038/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5039/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5040/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5041/10000..  Training Loss: 0.937..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5042/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5043/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5044/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5045/10000..  Training Loss: 0.936..  Test Loss: 1.104..  Test Accuracy: 0.802\n",
            "Epoch: 5046/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5047/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5048/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5049/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.781\n",
            "Epoch: 5050/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5051/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5052/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5053/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5054/10000..  Training Loss: 0.936..  Test Loss: 1.104..  Test Accuracy: 0.802\n",
            "Epoch: 5055/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.818\n",
            "Epoch: 5056/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5057/10000..  Training Loss: 0.936..  Test Loss: 1.104..  Test Accuracy: 0.802\n",
            "Epoch: 5058/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5059/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5060/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5061/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5062/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5063/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5064/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5065/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5066/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5067/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5068/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5069/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5070/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.818\n",
            "Epoch: 5071/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5072/10000..  Training Loss: 0.936..  Test Loss: 1.108..  Test Accuracy: 0.802\n",
            "Epoch: 5073/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5074/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5075/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5076/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5077/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5078/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5079/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5080/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5081/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5082/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5083/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5084/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5085/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5086/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5087/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5088/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5089/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5090/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5091/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5092/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5093/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5094/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5095/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.802\n",
            "Epoch: 5096/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5097/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5098/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5099/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5100/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5101/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5102/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5103/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5104/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5105/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5106/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5107/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5108/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5109/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5110/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5111/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5112/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5113/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5114/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.797\n",
            "Epoch: 5115/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5116/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.802\n",
            "Epoch: 5117/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5118/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5119/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5120/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5121/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5122/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5123/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5124/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5125/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5126/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5127/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5128/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5129/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5130/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5131/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5132/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5133/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5134/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.802\n",
            "Epoch: 5135/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5136/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5137/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5138/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5139/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5140/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5141/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5142/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5143/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5144/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5145/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5146/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5147/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5148/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5149/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5150/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5151/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5152/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5153/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5154/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5155/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5156/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5157/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5158/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5159/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5160/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5161/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5162/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5163/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5164/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5165/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5166/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5167/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5168/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5169/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5170/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5171/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5172/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5173/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5174/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5175/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5176/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.802\n",
            "Epoch: 5177/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5178/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5179/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5180/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5181/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5182/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5183/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5184/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5185/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5186/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5187/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5188/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5189/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5190/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5191/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5192/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.802\n",
            "Epoch: 5193/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5194/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5195/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5196/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5197/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5198/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5199/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5200/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5201/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5202/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5203/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5204/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5205/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5206/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5207/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5208/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5209/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5210/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5211/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5212/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5213/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5214/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5215/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5216/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5217/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5218/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5219/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5220/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5221/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5222/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5223/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5224/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5225/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5226/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5227/10000..  Training Loss: 0.936..  Test Loss: 1.104..  Test Accuracy: 0.802\n",
            "Epoch: 5228/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5229/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5230/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5231/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5232/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5233/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5234/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5235/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5236/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5237/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5238/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5239/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5240/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5241/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5242/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5243/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5244/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5245/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5246/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5247/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5248/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5249/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5250/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5251/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5252/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5253/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5254/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5255/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5256/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5257/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5258/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5259/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5260/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5261/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5262/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5263/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5264/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5265/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5266/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5267/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5268/10000..  Training Loss: 0.936..  Test Loss: 1.106..  Test Accuracy: 0.802\n",
            "Epoch: 5269/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5270/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5271/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5272/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5273/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5274/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5275/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5276/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5277/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5278/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5279/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5280/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5281/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5282/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5283/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5284/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5285/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5286/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5287/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5288/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5289/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5290/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5291/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5292/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5293/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5294/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5295/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5296/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5297/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.818\n",
            "Epoch: 5298/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5299/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5300/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5301/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5302/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5303/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5304/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5305/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5306/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5307/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5308/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5309/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5310/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5311/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5312/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5313/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5314/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5315/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5316/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5317/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5318/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5319/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5320/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5321/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5322/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5323/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5324/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5325/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5326/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5327/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5328/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5329/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5330/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5331/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5332/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5333/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5334/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5335/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5336/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5337/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5338/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5339/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5340/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5341/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5342/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5343/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5344/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5345/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5346/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5347/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5348/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5349/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5350/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5351/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5352/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5353/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5354/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5355/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5356/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5357/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5358/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5359/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5360/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5361/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5362/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5363/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5364/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5365/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5366/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5367/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5368/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5369/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5370/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5371/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5372/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5373/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5374/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5375/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5376/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5377/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5378/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5379/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5380/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.818\n",
            "Epoch: 5381/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5382/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5383/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5384/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5385/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5386/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5387/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5388/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5389/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5390/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5391/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5392/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5393/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5394/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5395/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5396/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5397/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5398/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5399/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5400/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5401/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5402/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.818\n",
            "Epoch: 5403/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5404/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5405/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5406/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5407/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.818\n",
            "Epoch: 5408/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5409/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5410/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5411/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.818\n",
            "Epoch: 5412/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5413/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.802\n",
            "Epoch: 5414/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5415/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5416/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5417/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5418/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5419/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5420/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5421/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5422/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5423/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5424/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5425/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5426/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5427/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5428/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5429/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5430/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5431/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5432/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5433/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5434/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5435/10000..  Training Loss: 0.936..  Test Loss: 1.097..  Test Accuracy: 0.802\n",
            "Epoch: 5436/10000..  Training Loss: 0.936..  Test Loss: 1.095..  Test Accuracy: 0.802\n",
            "Epoch: 5437/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5438/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5439/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5440/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5441/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5442/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5443/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5444/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5445/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5446/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5447/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5448/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5449/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5450/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5451/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5452/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5453/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5454/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5455/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5456/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5457/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5458/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5459/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5460/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5461/10000..  Training Loss: 0.936..  Test Loss: 1.100..  Test Accuracy: 0.802\n",
            "Epoch: 5462/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5463/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5464/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5465/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.818\n",
            "Epoch: 5466/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5467/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5468/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5469/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5470/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5471/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5472/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5473/10000..  Training Loss: 0.936..  Test Loss: 1.087..  Test Accuracy: 0.818\n",
            "Epoch: 5474/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5475/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5476/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5477/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5478/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5479/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5480/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5481/10000..  Training Loss: 0.936..  Test Loss: 1.093..  Test Accuracy: 0.818\n",
            "Epoch: 5482/10000..  Training Loss: 0.936..  Test Loss: 1.091..  Test Accuracy: 0.818\n",
            "Epoch: 5483/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.818\n",
            "Epoch: 5484/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5485/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5486/10000..  Training Loss: 0.936..  Test Loss: 1.094..  Test Accuracy: 0.802\n",
            "Epoch: 5487/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5488/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5489/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5490/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5491/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5492/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5493/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5494/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5495/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5496/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5497/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5498/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5499/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5500/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5501/10000..  Training Loss: 0.936..  Test Loss: 1.098..  Test Accuracy: 0.802\n",
            "Epoch: 5502/10000..  Training Loss: 0.936..  Test Loss: 1.102..  Test Accuracy: 0.802\n",
            "Epoch: 5503/10000..  Training Loss: 0.936..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5504/10000..  Training Loss: 0.936..  Test Loss: 1.096..  Test Accuracy: 0.818\n",
            "Epoch: 5505/10000..  Training Loss: 0.936..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
            "Epoch: 5506/10000..  Training Loss: 0.936..  Test Loss: 1.089..  Test Accuracy: 0.818\n",
            "Epoch: 5507/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5508/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5509/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5510/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5511/10000..  Training Loss: 0.936..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
            "Epoch: 5512/10000..  Training Loss: 0.936..  Test Loss: 1.099..  Test Accuracy: 0.802\n",
            "Epoch: 5513/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5514/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5515/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5516/10000..  Training Loss: 0.936..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
            "Epoch: 5517/10000..  Training Loss: 0.940..  Test Loss: 1.101..  Test Accuracy: 0.802\n",
            "Epoch: 5518/10000..  Training Loss: 0.936..  Test Loss: 1.103..  Test Accuracy: 0.802\n",
            "Epoch: 5519/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5520/10000..  Training Loss: 0.942..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5521/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5522/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5523/10000..  Training Loss: 0.936..  Test Loss: 1.140..  Test Accuracy: 0.766\n",
            "Epoch: 5524/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5525/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5526/10000..  Training Loss: 0.936..  Test Loss: 1.158..  Test Accuracy: 0.745\n",
            "Epoch: 5527/10000..  Training Loss: 0.936..  Test Loss: 1.158..  Test Accuracy: 0.745\n",
            "Epoch: 5528/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.786\n",
            "Epoch: 5529/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5530/10000..  Training Loss: 0.936..  Test Loss: 1.144..  Test Accuracy: 0.766\n",
            "Epoch: 5531/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5532/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5533/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5534/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5535/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5536/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5537/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5538/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5539/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5540/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5541/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5542/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5543/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5544/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5545/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5546/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5547/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5548/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5549/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5550/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5551/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5552/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5553/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5554/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5555/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5556/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5557/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5558/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5559/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5560/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5561/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5562/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5563/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5564/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5565/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5566/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5567/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5568/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5569/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5570/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5571/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5572/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5573/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5574/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5575/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5576/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5577/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5578/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5579/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5580/10000..  Training Loss: 0.936..  Test Loss: 1.116..  Test Accuracy: 0.786\n",
            "Epoch: 5581/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5582/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5583/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5584/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5585/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5586/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5587/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5588/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5589/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5590/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5591/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5592/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5593/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5594/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5595/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5596/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5597/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5598/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5599/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5600/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5601/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5602/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5603/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5604/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5605/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5606/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5607/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5608/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5609/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5610/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5611/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5612/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5613/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5614/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5615/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5616/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5617/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5618/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5619/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5620/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5621/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5622/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5623/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5624/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5625/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5626/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5627/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5628/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5629/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5630/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5631/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5632/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5633/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5634/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5635/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5636/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5637/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5638/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5639/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5640/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5641/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5642/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5643/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5644/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5645/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5646/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5647/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5648/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5649/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5650/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5651/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5652/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5653/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5654/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5655/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5656/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5657/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5658/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5659/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5660/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5661/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5662/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5663/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5664/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5665/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5666/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5667/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5668/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5669/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5670/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5671/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5672/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5673/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5674/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5675/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5676/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5677/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5678/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5679/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5680/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5681/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5682/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5683/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5684/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5685/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5686/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5687/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5688/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5689/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5690/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5691/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5692/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5693/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5694/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5695/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5696/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5697/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5698/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5699/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5700/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5701/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5702/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5703/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5704/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5705/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5706/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5707/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5708/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5709/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5710/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5711/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5712/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5713/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5714/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5715/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5716/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5717/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5718/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5719/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5720/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5721/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5722/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5723/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5724/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5725/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5726/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5727/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5728/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5729/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5730/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5731/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5732/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5733/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5734/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5735/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5736/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5737/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5738/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5739/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5740/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5741/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5742/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5743/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5744/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5745/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5746/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5747/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5748/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5749/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5750/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5751/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5752/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5753/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5754/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5755/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5756/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5757/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5758/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5759/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5760/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5761/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5762/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5763/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5764/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5765/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5766/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5767/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5768/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5769/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5770/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5771/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5772/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5773/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5774/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5775/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5776/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5777/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5778/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5779/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5780/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5781/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5782/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5783/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5784/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5785/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5786/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5787/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5788/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5789/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5790/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5791/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5792/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5793/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5794/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5795/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5796/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5797/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5798/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5799/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5800/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5801/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5802/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5803/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5804/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5805/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5806/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5807/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5808/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5809/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5810/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5811/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5812/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5813/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5814/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5815/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5816/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5817/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5818/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5819/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5820/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5821/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5822/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5823/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5824/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5825/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5826/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5827/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5828/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5829/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5830/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5831/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5832/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5833/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5834/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5835/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5836/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5837/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5838/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5839/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5840/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5841/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5842/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5843/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5844/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5845/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 5846/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5847/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5848/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5849/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5850/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5851/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5852/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5853/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5854/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5855/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5856/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5857/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5858/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5859/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5860/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5861/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5862/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5863/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5864/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5865/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5866/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5867/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5868/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5869/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5870/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5871/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5872/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5873/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5874/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5875/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5876/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5877/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5878/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5879/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5880/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5881/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5882/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5883/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5884/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5885/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5886/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5887/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5888/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5889/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5890/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5891/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5892/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5893/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5894/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5895/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5896/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5897/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5898/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5899/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5900/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5901/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5902/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5903/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5904/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5905/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 5906/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5907/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5908/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5909/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 5910/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5911/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5912/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5913/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5914/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5915/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5916/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5917/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5918/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5919/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5920/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5921/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5922/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5923/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5924/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5925/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5926/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5927/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5928/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5929/10000..  Training Loss: 0.936..  Test Loss: 1.113..  Test Accuracy: 0.802\n",
            "Epoch: 5930/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5931/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 5932/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5933/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5934/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5935/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5936/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 5937/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5938/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 5939/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5940/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5941/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5942/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5943/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 5944/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 5945/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5946/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5947/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5948/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5949/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5950/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 5951/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5952/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 5953/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 5954/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5955/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5956/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5957/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5958/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5959/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5960/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5961/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5962/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5963/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5964/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5965/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5966/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5967/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5968/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 5969/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 5970/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5971/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5972/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5973/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5974/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5975/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5976/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5977/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5978/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5979/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 5980/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 5981/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5982/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5983/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5984/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5985/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 5986/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5987/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5988/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 5989/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5990/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5991/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 5992/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 5993/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 5994/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 5995/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5996/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5997/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 5998/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 5999/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6000/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6001/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6002/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6003/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6004/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6005/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6006/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6007/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6008/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6009/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6010/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6011/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6012/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6013/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6014/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6015/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6016/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6017/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6018/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6019/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6020/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6021/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6022/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6023/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6024/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6025/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6026/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6027/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6028/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6029/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6030/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6031/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6032/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6033/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6034/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6035/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6036/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6037/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6038/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6039/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6040/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6041/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6042/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6043/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6044/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6045/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6046/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6047/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6048/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6049/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6050/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6051/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6052/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6053/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6054/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6055/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6056/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6057/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6058/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6059/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6060/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6061/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6062/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6063/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6064/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6065/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6066/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6067/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6068/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6069/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6070/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6071/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6072/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6073/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6074/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6075/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6076/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6077/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6078/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6079/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6080/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6081/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6082/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6083/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6084/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6085/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6086/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6087/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6088/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6089/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6090/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6091/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6092/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6093/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6094/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6095/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6096/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6097/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6098/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6099/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6100/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6101/10000..  Training Loss: 0.936..  Test Loss: 1.116..  Test Accuracy: 0.786\n",
            "Epoch: 6102/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6103/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6104/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6105/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6106/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6107/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6108/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6109/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6110/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6111/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6112/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6113/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6114/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6115/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6116/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6117/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6118/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6119/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6120/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6121/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6122/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6123/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6124/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6125/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6126/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6127/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6128/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6129/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6130/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6131/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6132/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6133/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 6134/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6135/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6136/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6137/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6138/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6139/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6140/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6141/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6142/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6143/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6144/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6145/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6146/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6147/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6148/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6149/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6150/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6151/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6152/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6153/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6154/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6155/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6156/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6157/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6158/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6159/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6160/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6161/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6162/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6163/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6164/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6165/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6166/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6167/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6168/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6169/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6170/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6171/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6172/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6173/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6174/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6175/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6176/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6177/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6178/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6179/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6180/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6181/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6182/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6183/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6184/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6185/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6186/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6187/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6188/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6189/10000..  Training Loss: 0.936..  Test Loss: 1.116..  Test Accuracy: 0.786\n",
            "Epoch: 6190/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6191/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6192/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6193/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6194/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6195/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6196/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6197/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6198/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6199/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6200/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6201/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6202/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6203/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6204/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6205/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6206/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6207/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6208/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6209/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6210/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6211/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6212/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6213/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6214/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6215/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6216/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6217/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6218/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6219/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6220/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6221/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6222/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6223/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6224/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6225/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6226/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6227/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6228/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6229/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6230/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6231/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6232/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6233/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6234/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6235/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6236/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6237/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6238/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6239/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6240/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6241/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6242/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6243/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6244/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6245/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6246/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6247/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6248/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6249/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6250/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6251/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6252/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6253/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6254/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6255/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6256/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6257/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6258/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6259/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6260/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6261/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6262/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6263/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6264/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6265/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6266/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6267/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6268/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6269/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6270/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6271/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6272/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6273/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6274/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6275/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6276/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6277/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6278/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6279/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6280/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6281/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6282/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6283/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6284/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6285/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6286/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6287/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6288/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6289/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6290/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6291/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6292/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6293/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6294/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6295/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6296/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6297/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6298/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6299/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6300/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6301/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6302/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6303/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6304/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6305/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6306/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6307/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6308/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6309/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6310/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6311/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6312/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6313/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6314/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6315/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6316/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6317/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6318/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6319/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6320/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6321/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6322/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6323/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6324/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6325/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6326/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6327/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6328/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6329/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6330/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6331/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6332/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6333/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6334/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6335/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6336/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6337/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6338/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6339/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6340/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6341/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6342/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6343/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6344/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6345/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6346/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6347/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6348/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6349/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6350/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6351/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6352/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6353/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6354/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6355/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 6356/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6357/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6358/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6359/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6360/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6361/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6362/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6363/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6364/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6365/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6366/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6367/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6368/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6369/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6370/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6371/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6372/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6373/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6374/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6375/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6376/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6377/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6378/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6379/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6380/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6381/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6382/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6383/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6384/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6385/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6386/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6387/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6388/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6389/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6390/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6391/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6392/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6393/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6394/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6395/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6396/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6397/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6398/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6399/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6400/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6401/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6402/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6403/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6404/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6405/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6406/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6407/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6408/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6409/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6410/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6411/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6412/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6413/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6414/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6415/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6416/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6417/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6418/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6419/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6420/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6421/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6422/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6423/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6424/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6425/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6426/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6427/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6428/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6429/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6430/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6431/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6432/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6433/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6434/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6435/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6436/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6437/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6438/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6439/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6440/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6441/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6442/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6443/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6444/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6445/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6446/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6447/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6448/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6449/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6450/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6451/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6452/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6453/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6454/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6455/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6456/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6457/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6458/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6459/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6460/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6461/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6462/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6463/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6464/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6465/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6466/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6467/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6468/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6469/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6470/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6471/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6472/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6473/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6474/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6475/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6476/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6477/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6478/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6479/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6480/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6481/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6482/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6483/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6484/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6485/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6486/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6487/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6488/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6489/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6490/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6491/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6492/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6493/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6494/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6495/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6496/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6497/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6498/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6499/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6500/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6501/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6502/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6503/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6504/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6505/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6506/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6507/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6508/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6509/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6510/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6511/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6512/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6513/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6514/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6515/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6516/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6517/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6518/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6519/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6520/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6521/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6522/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6523/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6524/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6525/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6526/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6527/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6528/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6529/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6530/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6531/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6532/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6533/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6534/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6535/10000..  Training Loss: 0.936..  Test Loss: 1.116..  Test Accuracy: 0.786\n",
            "Epoch: 6536/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6537/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6538/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6539/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6540/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6541/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6542/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6543/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6544/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6545/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6546/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6547/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6548/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6549/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6550/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6551/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6552/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6553/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6554/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6555/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6556/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6557/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6558/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6559/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6560/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6561/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6562/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6563/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6564/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6565/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6566/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6567/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6568/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6569/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6570/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6571/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6572/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6573/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6574/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6575/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6576/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6577/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6578/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6579/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6580/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6581/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6582/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6583/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6584/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6585/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6586/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6587/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6588/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6589/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6590/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6591/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6592/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6593/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6594/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6595/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6596/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6597/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6598/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6599/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6600/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6601/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6602/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6603/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6604/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6605/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6606/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6607/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6608/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6609/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6610/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6611/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6612/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6613/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6614/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6615/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6616/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6617/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6618/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6619/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6620/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6621/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6622/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6623/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6624/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6625/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6626/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6627/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6628/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6629/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6630/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6631/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6632/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6633/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6634/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6635/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6636/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6637/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6638/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6639/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6640/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6641/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6642/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6643/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6644/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6645/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6646/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6647/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 6648/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6649/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6650/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6651/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6652/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6653/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6654/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6655/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6656/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6657/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6658/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6659/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6660/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6661/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6662/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6663/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6664/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6665/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6666/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6667/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6668/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6669/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6670/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6671/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6672/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6673/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6674/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6675/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6676/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6677/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6678/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6679/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6680/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6681/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6682/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6683/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6684/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6685/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6686/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6687/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6688/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6689/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6690/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6691/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6692/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6693/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6694/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6695/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6696/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6697/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6698/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6699/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6700/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6701/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6702/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6703/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6704/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6705/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6706/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6707/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6708/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6709/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6710/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6711/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6712/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6713/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6714/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6715/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6716/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6717/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6718/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6719/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6720/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6721/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6722/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6723/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6724/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6725/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6726/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6727/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6728/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6729/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6730/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6731/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6732/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6733/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6734/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6735/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6736/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6737/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6738/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6739/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6740/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6741/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6742/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6743/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6744/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6745/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6746/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6747/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6748/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6749/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6750/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6751/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6752/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6753/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6754/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6755/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6756/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6757/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6758/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6759/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6760/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6761/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6762/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6763/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6764/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6765/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6766/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6767/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6768/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6769/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6770/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6771/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6772/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6773/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6774/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6775/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6776/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6777/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6778/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6779/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6780/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6781/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6782/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6783/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6784/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6785/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6786/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6787/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6788/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6789/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6790/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6791/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6792/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6793/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6794/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6795/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 6796/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6797/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6798/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6799/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6800/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6801/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6802/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6803/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6804/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6805/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6806/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6807/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6808/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6809/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6810/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6811/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6812/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6813/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6814/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6815/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6816/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6817/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6818/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6819/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6820/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6821/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6822/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6823/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6824/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6825/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6826/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6827/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6828/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6829/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6830/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6831/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6832/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6833/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6834/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6835/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6836/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6837/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6838/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6839/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6840/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6841/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6842/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6843/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6844/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6845/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6846/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6847/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6848/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6849/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6850/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6851/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6852/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6853/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6854/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6855/10000..  Training Loss: 0.936..  Test Loss: 1.113..  Test Accuracy: 0.786\n",
            "Epoch: 6856/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6857/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6858/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6859/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6860/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6861/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6862/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6863/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6864/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6865/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6866/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6867/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6868/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6869/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 6870/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6871/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6872/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6873/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6874/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6875/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6876/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6877/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6878/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6879/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6880/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6881/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6882/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6883/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6884/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6885/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6886/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6887/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6888/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6889/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 6890/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6891/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6892/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6893/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6894/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6895/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6896/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6897/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6898/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6899/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6900/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6901/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6902/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6903/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6904/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6905/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6906/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6907/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6908/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6909/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6910/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6911/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6912/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6913/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6914/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6915/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6916/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6917/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6918/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6919/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6920/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6921/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6922/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 6923/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6924/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6925/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6926/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6927/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6928/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6929/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6930/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6931/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6932/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 6933/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 6934/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 6935/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6936/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6937/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6938/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6939/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 6940/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 6941/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6942/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6943/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6944/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6945/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6946/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6947/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6948/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6949/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 6950/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6951/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6952/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 6953/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 6954/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6955/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6956/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6957/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6958/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6959/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6960/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6961/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6962/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6963/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6964/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6965/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6966/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 6967/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6968/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6969/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6970/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6971/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6972/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 6973/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6974/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6975/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6976/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6977/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6978/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6979/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6980/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6981/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 6982/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6983/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6984/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6985/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6986/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6987/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6988/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6989/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 6990/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 6991/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6992/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 6993/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 6994/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6995/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 6996/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 6997/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 6998/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 6999/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7000/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7001/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7002/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7003/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7004/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7005/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7006/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7007/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7008/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7009/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7010/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7011/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7012/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7013/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7014/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7015/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7016/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7017/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7018/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7019/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7020/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7021/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7022/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7023/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7024/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7025/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7026/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7027/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7028/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7029/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7030/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7031/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7032/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7033/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7034/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7035/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7036/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7037/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7038/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7039/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7040/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7041/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7042/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7043/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7044/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7045/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7046/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7047/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7048/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7049/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7050/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7051/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7052/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7053/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7054/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7055/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7056/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7057/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7058/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7059/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7060/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7061/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7062/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7063/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7064/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7065/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7066/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7067/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7068/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7069/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7070/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7071/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7072/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7073/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7074/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7075/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7076/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7077/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7078/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7079/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7080/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7081/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7082/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7083/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7084/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7085/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7086/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7087/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7088/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7089/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7090/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7091/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7092/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7093/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7094/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7095/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7096/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7097/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7098/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7099/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7100/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7101/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7102/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7103/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7104/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7105/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7106/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7107/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7108/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7109/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7110/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7111/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7112/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7113/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7114/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7115/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7116/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7117/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7118/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7119/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7120/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7121/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7122/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7123/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7124/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7125/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7126/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7127/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7128/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7129/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7130/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7131/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7132/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7133/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7134/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7135/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7136/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7137/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7138/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7139/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7140/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7141/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7142/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7143/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7144/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7145/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7146/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7147/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7148/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7149/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7150/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7151/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7152/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7153/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7154/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7155/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7156/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7157/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7158/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7159/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7160/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7161/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7162/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7163/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7164/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7165/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7166/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7167/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7168/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7169/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7170/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7171/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7172/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7173/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7174/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7175/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7176/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7177/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7178/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7179/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7180/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7181/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7182/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7183/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7184/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7185/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7186/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7187/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7188/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7189/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7190/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7191/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7192/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7193/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7194/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7195/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7196/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7197/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7198/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7199/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7200/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 7201/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7202/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7203/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7204/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7205/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7206/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7207/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7208/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7209/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7210/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7211/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7212/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7213/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7214/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7215/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7216/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7217/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7218/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7219/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7220/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7221/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7222/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7223/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7224/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7225/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7226/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7227/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7228/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7229/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7230/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7231/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7232/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7233/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7234/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7235/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7236/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7237/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7238/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7239/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7240/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7241/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7242/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7243/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7244/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7245/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7246/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7247/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7248/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7249/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7250/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7251/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7252/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7253/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7254/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7255/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7256/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7257/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7258/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7259/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7260/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7261/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7262/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7263/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7264/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7265/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7266/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7267/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7268/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7269/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7270/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7271/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7272/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7273/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7274/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7275/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7276/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7277/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7278/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7279/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7280/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7281/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7282/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7283/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7284/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7285/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7286/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7287/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7288/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7289/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7290/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7291/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7292/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7293/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7294/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7295/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7296/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7297/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7298/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7299/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7300/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7301/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7302/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7303/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7304/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7305/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7306/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7307/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7308/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7309/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7310/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7311/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7312/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7313/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7314/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7315/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7316/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7317/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7318/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7319/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7320/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7321/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7322/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7323/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7324/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7325/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7326/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7327/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7328/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7329/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7330/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7331/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7332/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7333/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7334/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7335/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7336/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7337/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7338/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7339/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7340/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7341/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7342/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7343/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7344/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7345/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7346/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7347/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7348/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7349/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7350/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7351/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7352/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7353/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7354/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7355/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7356/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7357/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7358/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7359/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7360/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7361/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7362/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7363/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7364/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7365/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7366/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7367/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7368/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7369/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7370/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7371/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7372/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7373/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7374/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7375/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7376/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7377/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7378/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7379/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7380/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7381/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7382/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7383/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7384/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7385/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7386/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7387/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7388/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7389/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7390/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7391/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7392/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7393/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7394/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7395/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7396/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7397/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7398/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7399/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7400/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7401/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7402/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7403/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7404/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7405/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 7406/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7407/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7408/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7409/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7410/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7411/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7412/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7413/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7414/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7415/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7416/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7417/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7418/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7419/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7420/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7421/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7422/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7423/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7424/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7425/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7426/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7427/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7428/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7429/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7430/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7431/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7432/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7433/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7434/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7435/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7436/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7437/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7438/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7439/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7440/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7441/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7442/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7443/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7444/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7445/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7446/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7447/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7448/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7449/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7450/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7451/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7452/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7453/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7454/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7455/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7456/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7457/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7458/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7459/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7460/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7461/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7462/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7463/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7464/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7465/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7466/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7467/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7468/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7469/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7470/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7471/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7472/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7473/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7474/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7475/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7476/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7477/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7478/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7479/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7480/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7481/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7482/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7483/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7484/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7485/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7486/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7487/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7488/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7489/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7490/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7491/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7492/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7493/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7494/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7495/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7496/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7497/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7498/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7499/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7500/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7501/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7502/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7503/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7504/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7505/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7506/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7507/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7508/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7509/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7510/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7511/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7512/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7513/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7514/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7515/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7516/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7517/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7518/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7519/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7520/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7521/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7522/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7523/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7524/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7525/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7526/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7527/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7528/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7529/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7530/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7531/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7532/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7533/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7534/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7535/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7536/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7537/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7538/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7539/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7540/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7541/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7542/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7543/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7544/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7545/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7546/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7547/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7548/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7549/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7550/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7551/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7552/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7553/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7554/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7555/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7556/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7557/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7558/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7559/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7560/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7561/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7562/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7563/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7564/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7565/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7566/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7567/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7568/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7569/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7570/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7571/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7572/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7573/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7574/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7575/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7576/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7577/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7578/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7579/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7580/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7581/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7582/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7583/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7584/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7585/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7586/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7587/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7588/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7589/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7590/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7591/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7592/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7593/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7594/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7595/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7596/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7597/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7598/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7599/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7600/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7601/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7602/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7603/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7604/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7605/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7606/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7607/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7608/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7609/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7610/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7611/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7612/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7613/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7614/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7615/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7616/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7617/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7618/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7619/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7620/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7621/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7622/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7623/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7624/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7625/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7626/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7627/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7628/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7629/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7630/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7631/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7632/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7633/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7634/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7635/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7636/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7637/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7638/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7639/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7640/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7641/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7642/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7643/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7644/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7645/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7646/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7647/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7648/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7649/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7650/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7651/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7652/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7653/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7654/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7655/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7656/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7657/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7658/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7659/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7660/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7661/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7662/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7663/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7664/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7665/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7666/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7667/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7668/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7669/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7670/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7671/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7672/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7673/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7674/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7675/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7676/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7677/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7678/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7679/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7680/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7681/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7682/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7683/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7684/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7685/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7686/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7687/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7688/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7689/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7690/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7691/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7692/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7693/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7694/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7695/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7696/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7697/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7698/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7699/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7700/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7701/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7702/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7703/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7704/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7705/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7706/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7707/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7708/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7709/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7710/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7711/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7712/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7713/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7714/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7715/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7716/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7717/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7718/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7719/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7720/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7721/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7722/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7723/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7724/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7725/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7726/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7727/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7728/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7729/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7730/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7731/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7732/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7733/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7734/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7735/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7736/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7737/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7738/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7739/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7740/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7741/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7742/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7743/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7744/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7745/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7746/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7747/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7748/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7749/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7750/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7751/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7752/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7753/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7754/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7755/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7756/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7757/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7758/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7759/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7760/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7761/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7762/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7763/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7764/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7765/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7766/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7767/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7768/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7769/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7770/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7771/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7772/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7773/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7774/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7775/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7776/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7777/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7778/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7779/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7780/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7781/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7782/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7783/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7784/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7785/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7786/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7787/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7788/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7789/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7790/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7791/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7792/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7793/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7794/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7795/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7796/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7797/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7798/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7799/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7800/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7801/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7802/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7803/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7804/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7805/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7806/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7807/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7808/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7809/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7810/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7811/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7812/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7813/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7814/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7815/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7816/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7817/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7818/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7819/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7820/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7821/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7822/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7823/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7824/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7825/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7826/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7827/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7828/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7829/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7830/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 7831/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7832/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7833/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7834/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7835/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7836/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7837/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7838/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7839/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7840/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7841/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 7842/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7843/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7844/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7845/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7846/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7847/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7848/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7849/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7850/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7851/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7852/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7853/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7854/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7855/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7856/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7857/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7858/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7859/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7860/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7861/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7862/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7863/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 7864/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7865/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7866/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7867/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7868/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7869/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7870/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7871/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 7872/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7873/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7874/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7875/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7876/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7877/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7878/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7879/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7880/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7881/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7882/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7883/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7884/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7885/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7886/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7887/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7888/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7889/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7890/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7891/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7892/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7893/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7894/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7895/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7896/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7897/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7898/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7899/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7900/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7901/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7902/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7903/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7904/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7905/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7906/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7907/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7908/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7909/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7910/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7911/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7912/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7913/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7914/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7915/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7916/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7917/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 7918/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7919/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7920/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7921/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7922/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7923/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7924/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7925/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7926/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7927/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7928/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7929/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7930/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7931/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7932/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7933/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7934/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7935/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7936/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7937/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7938/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 7939/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7940/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 7941/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7942/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7943/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7944/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7945/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7946/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7947/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 7948/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7949/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 7950/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7951/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7952/10000..  Training Loss: 0.936..  Test Loss: 1.116..  Test Accuracy: 0.786\n",
            "Epoch: 7953/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7954/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 7955/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7956/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7957/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7958/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7959/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 7960/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 7961/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 7962/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7963/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 7964/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 7965/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7966/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7967/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7968/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7969/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7970/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7971/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7972/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7973/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7974/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7975/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7976/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7977/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 7978/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7979/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7980/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7981/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 7982/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7983/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7984/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7985/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 7986/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 7987/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 7988/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7989/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7990/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7991/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7992/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7993/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 7994/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 7995/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 7996/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7997/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 7998/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 7999/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8000/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8001/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8002/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8003/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8004/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8005/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8006/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8007/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8008/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8009/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8010/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8011/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8012/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8013/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8014/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8015/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.766\n",
            "Epoch: 8016/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8017/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8018/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8019/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8020/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8021/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8022/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8023/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8024/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8025/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8026/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8027/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8028/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8029/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8030/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8031/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8032/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8033/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8034/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8035/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8036/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8037/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8038/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8039/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8040/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8041/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8042/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8043/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8044/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8045/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8046/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8047/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8048/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8049/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8050/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8051/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8052/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8053/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8054/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8055/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8056/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8057/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8058/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8059/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8060/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8061/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8062/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8063/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8064/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8065/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8066/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8067/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8068/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8069/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8070/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8071/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8072/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8073/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8074/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8075/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8076/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8077/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8078/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8079/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8080/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8081/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8082/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8083/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8084/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8085/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8086/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8087/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8088/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8089/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8090/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8091/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8092/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8093/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8094/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8095/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8096/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8097/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8098/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8099/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8100/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8101/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8102/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8103/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8104/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8105/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8106/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8107/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8108/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8109/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8110/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8111/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8112/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8113/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8114/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8115/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8116/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8117/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8118/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8119/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8120/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8121/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8122/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8123/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8124/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8125/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8126/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8127/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8128/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8129/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8130/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8131/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8132/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8133/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8134/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8135/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8136/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8137/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8138/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 8139/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8140/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8141/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8142/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8143/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8144/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8145/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8146/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8147/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8148/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8149/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8150/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8151/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8152/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8153/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8154/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8155/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8156/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8157/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8158/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8159/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8160/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8161/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8162/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8163/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8164/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8165/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8166/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8167/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8168/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8169/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8170/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8171/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8172/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8173/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8174/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8175/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8176/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8177/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8178/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8179/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8180/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8181/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8182/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8183/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8184/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8185/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8186/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8187/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8188/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8189/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8190/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8191/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8192/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8193/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8194/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8195/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8196/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8197/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8198/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8199/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8200/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8201/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8202/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8203/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8204/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8205/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8206/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8207/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8208/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8209/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8210/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8211/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8212/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8213/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8214/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8215/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8216/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8217/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8218/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8219/10000..  Training Loss: 0.936..  Test Loss: 1.115..  Test Accuracy: 0.786\n",
            "Epoch: 8220/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8221/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8222/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8223/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8224/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8225/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8226/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8227/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8228/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8229/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8230/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8231/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8232/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8233/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8234/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8235/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8236/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8237/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8238/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8239/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8240/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8241/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8242/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8243/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8244/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8245/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8246/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8247/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8248/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8249/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8250/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8251/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8252/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8253/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8254/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8255/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8256/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8257/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8258/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8259/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 8260/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8261/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8262/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8263/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8264/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8265/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8266/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8267/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8268/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8269/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8270/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8271/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8272/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8273/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8274/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8275/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8276/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8277/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8278/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8279/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8280/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8281/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8282/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8283/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8284/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8285/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8286/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8287/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8288/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8289/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8290/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8291/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8292/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8293/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8294/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8295/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8296/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8297/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8298/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8299/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8300/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8301/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8302/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8303/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8304/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8305/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8306/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8307/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8308/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8309/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8310/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 8311/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8312/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8313/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8314/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8315/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8316/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8317/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8318/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8319/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8320/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8321/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8322/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8323/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8324/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8325/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8326/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8327/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8328/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8329/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8330/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8331/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8332/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8333/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8334/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8335/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8336/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8337/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8338/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8339/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8340/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8341/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8342/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8343/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8344/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8345/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8346/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8347/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8348/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8349/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8350/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8351/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8352/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8353/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8354/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8355/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8356/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8357/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8358/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8359/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8360/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8361/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8362/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8363/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8364/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8365/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8366/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8367/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8368/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8369/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8370/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8371/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8372/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8373/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8374/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8375/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8376/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8377/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8378/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8379/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8380/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8381/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8382/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8383/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8384/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8385/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8386/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8387/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8388/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8389/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8390/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8391/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8392/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8393/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8394/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8395/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8396/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8397/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8398/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8399/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8400/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8401/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8402/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8403/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8404/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8405/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8406/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8407/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8408/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8409/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8410/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8411/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8412/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8413/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8414/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8415/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8416/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8417/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8418/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8419/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8420/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8421/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8422/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8423/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8424/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8425/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8426/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8427/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8428/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8429/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8430/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8431/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8432/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8433/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8434/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8435/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8436/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8437/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8438/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8439/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8440/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8441/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8442/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8443/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8444/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8445/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8446/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8447/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8448/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8449/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8450/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8451/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8452/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8453/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8454/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8455/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8456/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8457/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8458/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8459/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8460/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8461/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8462/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8463/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8464/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8465/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8466/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8467/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8468/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8469/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8470/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8471/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8472/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8473/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8474/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8475/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8476/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8477/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8478/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8479/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8480/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8481/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8482/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8483/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8484/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8485/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8486/10000..  Training Loss: 0.936..  Test Loss: 1.116..  Test Accuracy: 0.786\n",
            "Epoch: 8487/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8488/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8489/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8490/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8491/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8492/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8493/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8494/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8495/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8496/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8497/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8498/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8499/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8500/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8501/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8502/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8503/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8504/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8505/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8506/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8507/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8508/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8509/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8510/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8511/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8512/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8513/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8514/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8515/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8516/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8517/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8518/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8519/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8520/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8521/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8522/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8523/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8524/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8525/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8526/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8527/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8528/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8529/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8530/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8531/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8532/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8533/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8534/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8535/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8536/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8537/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8538/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8539/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8540/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8541/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8542/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8543/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8544/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8545/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8546/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8547/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8548/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8549/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8550/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8551/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8552/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8553/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8554/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8555/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8556/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8557/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8558/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8559/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8560/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8561/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8562/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8563/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8564/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8565/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8566/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8567/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8568/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.766\n",
            "Epoch: 8569/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8570/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8571/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8572/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8573/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8574/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8575/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8576/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8577/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8578/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8579/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8580/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8581/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8582/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8583/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8584/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8585/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8586/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8587/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8588/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8589/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8590/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8591/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8592/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8593/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8594/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8595/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8596/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8597/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8598/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8599/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8600/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8601/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8602/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8603/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8604/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8605/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8606/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8607/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8608/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8609/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8610/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8611/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8612/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8613/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8614/10000..  Training Loss: 0.936..  Test Loss: 1.104..  Test Accuracy: 0.802\n",
            "Epoch: 8615/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8616/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8617/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8618/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8619/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8620/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8621/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8622/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8623/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8624/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8625/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8626/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8627/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8628/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8629/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8630/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8631/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8632/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8633/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8634/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8635/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8636/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8637/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8638/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8639/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8640/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8641/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8642/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8643/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8644/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8645/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8646/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8647/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8648/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8649/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8650/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8651/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8652/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8653/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8654/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8655/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8656/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8657/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8658/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8659/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8660/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8661/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8662/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8663/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8664/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8665/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8666/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8667/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8668/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8669/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8670/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8671/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8672/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8673/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8674/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8675/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8676/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8677/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8678/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8679/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8680/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8681/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8682/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8683/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8684/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8685/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8686/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8687/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8688/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8689/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8690/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8691/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8692/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8693/10000..  Training Loss: 0.936..  Test Loss: 1.114..  Test Accuracy: 0.786\n",
            "Epoch: 8694/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8695/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8696/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8697/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8698/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8699/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8700/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8701/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8702/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8703/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8704/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8705/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8706/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8707/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8708/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8709/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8710/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8711/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8712/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8713/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8714/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8715/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8716/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8717/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8718/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8719/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8720/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8721/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8722/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8723/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8724/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8725/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8726/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8727/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8728/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8729/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8730/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8731/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8732/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8733/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8734/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8735/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8736/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8737/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8738/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8739/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8740/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8741/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8742/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8743/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8744/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8745/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8746/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8747/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8748/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8749/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8750/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8751/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8752/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8753/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8754/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8755/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8756/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8757/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8758/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8759/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8760/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8761/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8762/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8763/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8764/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8765/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8766/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8767/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8768/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8769/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8770/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8771/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8772/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8773/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8774/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8775/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8776/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8777/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8778/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8779/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8780/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 8781/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8782/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8783/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8784/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8785/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8786/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8787/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8788/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8789/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8790/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8791/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8792/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8793/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8794/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8795/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8796/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8797/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8798/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8799/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8800/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8801/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8802/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8803/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8804/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8805/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8806/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8807/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8808/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8809/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8810/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8811/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8812/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8813/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8814/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8815/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8816/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8817/10000..  Training Loss: 0.936..  Test Loss: 1.117..  Test Accuracy: 0.786\n",
            "Epoch: 8818/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8819/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8820/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8821/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8822/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8823/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8824/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8825/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8826/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8827/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8828/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8829/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8830/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8831/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8832/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8833/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8834/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8835/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8836/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8837/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8838/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8839/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8840/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8841/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8842/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8843/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8844/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8845/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8846/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8847/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8848/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8849/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 8850/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8851/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8852/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8853/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8854/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8855/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8856/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8857/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8858/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8859/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8860/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8861/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8862/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8863/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8864/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8865/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8866/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8867/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 8868/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8869/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8870/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8871/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8872/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8873/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8874/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8875/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8876/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8877/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8878/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8879/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8880/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8881/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8882/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8883/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8884/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8885/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8886/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8887/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8888/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8889/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8890/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8891/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8892/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8893/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8894/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8895/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8896/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8897/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8898/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8899/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8900/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8901/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8902/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8903/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8904/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8905/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8906/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8907/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8908/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8909/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8910/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8911/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8912/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8913/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8914/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8915/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 8916/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8917/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8918/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8919/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8920/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8921/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8922/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8923/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8924/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8925/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8926/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8927/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8928/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8929/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8930/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8931/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8932/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8933/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8934/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8935/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8936/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8937/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8938/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8939/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8940/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8941/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8942/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8943/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8944/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8945/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8946/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8947/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8948/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8949/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8950/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8951/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8952/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8953/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8954/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8955/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8956/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8957/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8958/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 8959/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8960/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8961/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8962/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8963/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8964/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8965/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 8966/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 8967/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8968/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 8969/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8970/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8971/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8972/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8973/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8974/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8975/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 8976/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8977/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 8978/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8979/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8980/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 8981/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8982/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 8983/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8984/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8985/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8986/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8987/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 8988/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 8989/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8990/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 8991/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8992/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 8993/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 8994/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 8995/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 8996/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 8997/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 8998/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 8999/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9000/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9001/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9002/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9003/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9004/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9005/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9006/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9007/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9008/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9009/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9010/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9011/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9012/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9013/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9014/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9015/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9016/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9017/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9018/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9019/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9020/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9021/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9022/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9023/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9024/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9025/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9026/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9027/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9028/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9029/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9030/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9031/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9032/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9033/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9034/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9035/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9036/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9037/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9038/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9039/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9040/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9041/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9042/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9043/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9044/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9045/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9046/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9047/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9048/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9049/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9050/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9051/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9052/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9053/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9054/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9055/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9056/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9057/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9058/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9059/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9060/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9061/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9062/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9063/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9064/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9065/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9066/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9067/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9068/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9069/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9070/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9071/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9072/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9073/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9074/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9075/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9076/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9077/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 9078/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9079/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9080/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9081/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9082/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9083/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9084/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9085/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9086/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9087/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9088/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9089/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9090/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9091/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9092/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9093/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9094/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9095/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9096/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9097/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9098/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9099/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9100/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9101/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9102/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9103/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9104/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9105/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9106/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9107/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9108/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9109/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9110/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9111/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9112/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9113/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9114/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9115/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9116/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9117/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9118/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9119/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9120/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9121/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9122/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9123/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9124/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9125/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9126/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9127/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9128/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9129/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9130/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9131/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9132/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9133/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9134/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9135/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9136/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9137/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9138/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9139/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9140/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9141/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9142/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9143/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9144/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9145/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9146/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9147/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9148/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9149/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9150/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9151/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9152/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9153/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9154/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9155/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9156/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9157/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9158/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9159/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9160/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9161/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9162/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9163/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9164/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9165/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9166/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9167/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9168/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9169/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9170/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9171/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9172/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9173/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9174/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9175/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9176/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9177/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9178/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9179/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9180/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9181/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9182/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9183/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9184/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9185/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9186/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9187/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9188/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9189/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9190/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9191/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9192/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9193/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9194/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9195/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9196/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9197/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9198/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9199/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9200/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9201/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9202/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9203/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9204/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9205/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9206/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9207/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9208/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9209/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9210/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9211/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9212/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9213/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9214/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9215/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9216/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9217/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9218/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9219/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9220/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9221/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9222/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9223/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9224/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9225/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9226/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9227/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9228/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9229/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9230/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9231/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9232/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9233/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9234/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9235/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9236/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9237/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9238/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9239/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9240/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9241/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9242/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9243/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9244/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9245/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9246/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9247/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9248/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9249/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9250/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9251/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9252/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9253/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9254/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9255/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9256/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9257/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9258/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9259/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9260/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9261/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9262/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9263/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9264/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9265/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9266/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9267/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9268/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9269/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9270/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9271/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9272/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9273/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9274/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9275/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9276/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9277/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9278/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9279/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9280/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9281/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9282/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9283/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9284/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9285/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9286/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9287/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9288/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9289/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9290/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9291/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9292/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9293/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9294/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9295/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9296/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9297/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9298/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9299/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9300/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9301/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9302/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9303/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9304/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9305/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9306/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9307/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9308/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9309/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9310/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9311/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9312/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9313/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9314/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9315/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9316/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9317/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9318/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9319/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9320/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9321/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9322/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9323/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9324/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9325/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9326/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9327/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9328/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9329/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9330/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9331/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9332/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9333/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9334/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9335/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9336/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9337/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9338/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9339/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9340/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9341/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9342/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9343/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9344/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9345/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9346/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9347/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9348/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9349/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9350/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9351/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9352/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9353/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.766\n",
            "Epoch: 9354/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9355/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9356/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9357/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9358/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9359/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9360/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9361/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9362/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9363/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9364/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9365/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9366/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9367/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9368/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9369/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9370/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9371/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9372/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9373/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9374/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9375/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9376/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9377/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9378/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9379/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9380/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9381/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9382/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9383/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9384/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9385/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9386/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9387/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9388/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9389/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9390/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9391/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9392/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9393/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9394/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9395/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9396/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9397/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9398/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9399/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9400/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9401/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9402/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9403/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9404/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9405/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9406/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9407/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9408/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9409/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9410/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9411/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9412/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9413/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9414/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9415/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9416/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9417/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9418/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9419/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9420/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9421/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9422/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9423/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9424/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9425/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9426/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9427/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9428/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9429/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9430/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9431/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9432/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9433/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9434/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9435/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9436/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9437/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9438/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9439/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9440/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9441/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9442/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9443/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9444/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9445/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9446/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9447/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9448/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9449/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9450/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9451/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9452/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9453/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9454/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9455/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9456/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9457/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9458/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9459/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9460/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9461/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9462/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9463/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9464/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9465/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9466/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9467/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9468/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9469/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9470/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9471/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9472/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9473/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9474/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9475/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9476/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9477/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9478/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9479/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9480/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9481/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9482/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9483/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9484/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9485/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9486/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9487/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9488/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9489/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9490/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9491/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9492/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9493/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9494/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9495/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9496/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9497/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9498/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9499/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9500/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9501/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9502/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9503/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9504/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9505/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9506/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9507/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9508/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9509/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9510/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9511/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9512/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9513/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9514/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9515/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9516/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9517/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9518/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9519/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9520/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9521/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9522/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9523/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9524/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9525/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9526/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9527/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9528/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9529/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9530/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9531/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9532/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9533/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9534/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9535/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9536/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9537/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9538/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9539/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9540/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9541/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9542/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9543/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9544/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9545/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9546/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9547/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9548/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9549/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9550/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9551/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9552/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9553/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9554/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9555/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9556/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9557/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9558/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9559/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9560/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9561/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9562/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9563/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9564/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9565/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9566/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9567/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9568/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9569/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9570/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9571/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9572/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9573/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9574/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9575/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9576/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9577/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9578/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9579/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9580/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9581/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9582/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9583/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9584/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9585/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9586/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9587/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9588/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9589/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9590/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9591/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9592/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9593/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9594/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9595/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9596/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9597/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9598/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9599/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9600/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9601/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9602/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9603/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9604/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9605/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9606/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9607/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9608/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9609/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9610/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9611/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9612/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9613/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9614/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9615/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9616/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9617/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9618/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9619/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9620/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9621/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9622/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9623/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9624/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9625/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9626/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9627/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9628/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9629/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9630/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9631/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9632/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9633/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9634/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9635/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9636/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9637/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9638/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9639/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9640/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9641/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9642/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9643/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9644/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9645/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9646/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9647/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9648/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9649/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9650/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9651/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9652/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9653/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9654/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9655/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9656/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9657/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9658/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9659/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9660/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9661/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9662/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9663/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9664/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9665/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9666/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9667/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9668/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9669/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9670/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9671/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9672/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9673/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9674/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9675/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9676/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9677/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9678/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9679/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9680/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9681/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9682/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9683/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9684/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9685/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9686/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9687/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9688/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9689/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9690/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9691/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9692/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9693/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9694/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9695/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9696/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9697/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9698/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9699/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9700/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9701/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9702/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9703/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9704/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9705/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9706/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9707/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9708/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9709/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9710/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9711/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9712/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9713/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9714/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9715/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9716/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9717/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9718/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9719/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9720/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9721/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9722/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9723/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9724/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9725/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9726/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9727/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9728/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9729/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9730/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9731/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9732/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9733/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9734/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9735/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9736/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9737/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9738/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9739/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9740/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9741/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9742/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9743/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9744/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9745/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9746/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9747/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9748/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9749/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9750/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9751/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9752/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9753/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9754/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9755/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9756/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9757/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9758/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9759/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9760/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9761/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9762/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9763/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9764/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9765/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9766/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9767/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9768/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9769/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9770/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9771/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9772/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9773/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9774/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9775/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9776/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9777/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9778/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9779/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9780/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9781/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9782/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9783/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9784/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9785/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9786/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9787/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9788/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9789/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9790/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9791/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9792/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9793/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9794/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9795/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9796/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9797/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9798/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9799/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9800/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9801/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9802/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9803/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9804/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9805/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9806/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9807/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9808/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9809/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9810/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9811/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9812/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9813/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9814/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9815/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9816/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9817/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9818/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9819/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9820/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9821/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9822/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9823/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9824/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9825/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9826/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9827/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9828/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9829/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9830/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9831/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9832/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9833/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9834/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9835/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9836/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9837/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9838/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9839/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9840/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9841/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9842/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9843/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9844/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9845/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9846/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9847/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9848/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9849/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9850/10000..  Training Loss: 0.936..  Test Loss: 1.130..  Test Accuracy: 0.766\n",
            "Epoch: 9851/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9852/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9853/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9854/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9855/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9856/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9857/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9858/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9859/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9860/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9861/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9862/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9863/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9864/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9865/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9866/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9867/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9868/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9869/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9870/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9871/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9872/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9873/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9874/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9875/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9876/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9877/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9878/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9879/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9880/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9881/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9882/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9883/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9884/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9885/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9886/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9887/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9888/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9889/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9890/10000..  Training Loss: 0.936..  Test Loss: 1.135..  Test Accuracy: 0.766\n",
            "Epoch: 9891/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9892/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9893/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9894/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9895/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9896/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9897/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9898/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9899/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9900/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9901/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9902/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9903/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9904/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9905/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9906/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9907/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9908/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9909/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9910/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9911/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9912/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9913/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9914/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9915/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9916/10000..  Training Loss: 0.936..  Test Loss: 1.134..  Test Accuracy: 0.766\n",
            "Epoch: 9917/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9918/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9919/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9920/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9921/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9922/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9923/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9924/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9925/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9926/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9927/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9928/10000..  Training Loss: 0.936..  Test Loss: 1.133..  Test Accuracy: 0.766\n",
            "Epoch: 9929/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9930/10000..  Training Loss: 0.936..  Test Loss: 1.126..  Test Accuracy: 0.786\n",
            "Epoch: 9931/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9932/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9933/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9934/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9935/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9936/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9937/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9938/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9939/10000..  Training Loss: 0.936..  Test Loss: 1.127..  Test Accuracy: 0.786\n",
            "Epoch: 9940/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9941/10000..  Training Loss: 0.936..  Test Loss: 1.131..  Test Accuracy: 0.766\n",
            "Epoch: 9942/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9943/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9944/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9945/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9946/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9947/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9948/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9949/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9950/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9951/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9952/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9953/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9954/10000..  Training Loss: 0.936..  Test Loss: 1.123..  Test Accuracy: 0.786\n",
            "Epoch: 9955/10000..  Training Loss: 0.936..  Test Loss: 1.128..  Test Accuracy: 0.766\n",
            "Epoch: 9956/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9957/10000..  Training Loss: 0.936..  Test Loss: 1.125..  Test Accuracy: 0.786\n",
            "Epoch: 9958/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9959/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9960/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9961/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9962/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9963/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9964/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9965/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9966/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9967/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9968/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9969/10000..  Training Loss: 0.936..  Test Loss: 1.136..  Test Accuracy: 0.766\n",
            "Epoch: 9970/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9971/10000..  Training Loss: 0.936..  Test Loss: 1.119..  Test Accuracy: 0.786\n",
            "Epoch: 9972/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9973/10000..  Training Loss: 0.936..  Test Loss: 1.118..  Test Accuracy: 0.786\n",
            "Epoch: 9974/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9975/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9976/10000..  Training Loss: 0.936..  Test Loss: 1.132..  Test Accuracy: 0.766\n",
            "Epoch: 9977/10000..  Training Loss: 0.936..  Test Loss: 1.137..  Test Accuracy: 0.766\n",
            "Epoch: 9978/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9979/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9980/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9981/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9982/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9983/10000..  Training Loss: 0.936..  Test Loss: 1.122..  Test Accuracy: 0.786\n",
            "Epoch: 9984/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9985/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9986/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9987/10000..  Training Loss: 0.936..  Test Loss: 1.129..  Test Accuracy: 0.766\n",
            "Epoch: 9988/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n",
            "Epoch: 9989/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9990/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9991/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9992/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9993/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 9994/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9995/10000..  Training Loss: 0.936..  Test Loss: 1.121..  Test Accuracy: 0.786\n",
            "Epoch: 9996/10000..  Training Loss: 0.936..  Test Loss: 1.124..  Test Accuracy: 0.786\n",
            "Epoch: 9997/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9998/10000..  Training Loss: 0.936..  Test Loss: 1.139..  Test Accuracy: 0.766\n",
            "Epoch: 9999/10000..  Training Loss: 0.936..  Test Loss: 1.120..  Test Accuracy: 0.786\n",
            "Epoch: 10000/10000..  Training Loss: 0.936..  Test Loss: 1.138..  Test Accuracy: 0.766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HHVnZ6m5_qV"
      },
      "source": [
        "## Testing the Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9z4JBWARDf",
        "outputId": "ce8f4ea8-31fd-4594-d107-73671ea229b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss = 0\n",
        "accuracy = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for sentences, labels in test_loader:\n",
        "        sentences, labels = sentences.to(device), labels.to(device)\n",
        "        ps = model(sentences)\n",
        "        test_loss += criterion(ps, labels).item()\n",
        "\n",
        "        # Accuracy\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "model.train()\n",
        "print(\"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "      \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
        "running_loss = 0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.139..  Test Accuracy: 0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egc4D90I6C6b"
      },
      "source": [
        "## Testing the model with any sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_xF0rcL6FRP"
      },
      "source": [
        "def predict(input_text, print_sentence=True):\n",
        "  labels_dict = {\n",
        "\t\t0 : \"‚ù§Ô∏è Loving\",\n",
        "\t\t1 : \"‚öΩÔ∏è Playful/Excited\",\n",
        "\t\t2 : \"üòÑ Happy\",\n",
        "\t\t3 : \"üòû Annoyed/Sad\",\n",
        "\t\t4 : \"üçΩ Foodie\",\n",
        "\t}\n",
        "\n",
        "  # Convert the input to the model\n",
        "  x_test = np.array([input_text])\n",
        "  X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "  sentences = torch.tensor(X_test_indices).type(torch.LongTensor)\n",
        "\n",
        "  # Get the class label\n",
        "  ps = model(sentences)\n",
        "  top_p, top_class = ps.topk(1, dim=1)\n",
        "  label = int(top_class[0][0])\n",
        "\n",
        "  if print_sentence:\n",
        "    print(\"\\nInput Text: \\t\"+ input_text +'\\nEmotion: \\t'+  labels_dict[label])\n",
        "\n",
        "  return label"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07i1a-R06J2n",
        "outputId": "8e5b8374-09e4-4785-ae5b-11a7d76ccc5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"------------------------------------\")\n",
        "predict(\"I hate you\")\n",
        "predict(\"I want a pizza\")\n",
        "predict(\"Lets see the game\")\n",
        "predict(\"I love you Lisa\")\n",
        "predict(\"This is the best day of my life\")\n",
        "predict(\"What the hell are you doing ?\")\n",
        "predict(\"Vishwanathan Anand won in chess !\")\n",
        "predict(\"She really likes you now\")\n",
        "predict(\"Kundu has won the table tennis championship\")\n",
        "predict(\"Donald Trump is a fool !\")\n",
        "predict(\"They are eating at the restaurant\")\n",
        "print(\"\\n------------------------------------\\n\")\n",
        "predict(\"He is reading the book \")\n",
        "predict(\"I cannot swim across the lake\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "\n",
            "Input Text: \tI hate you\n",
            "Emotion: \t‚ù§Ô∏è Loving\n",
            "\n",
            "Input Text: \tI want a pizza\n",
            "Emotion: \tüçΩ Foodie\n",
            "\n",
            "Input Text: \tLets see the game\n",
            "Emotion: \t‚öΩÔ∏è Playful/Excited\n",
            "\n",
            "Input Text: \tI love you Lisa\n",
            "Emotion: \t‚ù§Ô∏è Loving\n",
            "\n",
            "Input Text: \tThis is the best day of my life\n",
            "Emotion: \tüòÑ Happy\n",
            "\n",
            "Input Text: \tWhat the hell are you doing ?\n",
            "Emotion: \tüòû Annoyed/Sad\n",
            "\n",
            "Input Text: \tVishwanathan Anand won in chess !\n",
            "Emotion: \t‚öΩÔ∏è Playful/Excited\n",
            "\n",
            "Input Text: \tShe really likes you now\n",
            "Emotion: \t‚ù§Ô∏è Loving\n",
            "\n",
            "Input Text: \tKundu has won the table tennis championship\n",
            "Emotion: \t‚öΩÔ∏è Playful/Excited\n",
            "\n",
            "Input Text: \tDonald Trump is a fool !\n",
            "Emotion: \tüòÑ Happy\n",
            "\n",
            "Input Text: \tThey are eating at the restaurant\n",
            "Emotion: \tüçΩ Foodie\n",
            "\n",
            "------------------------------------\n",
            "\n",
            "\n",
            "Input Text: \tHe is reading the book \n",
            "Emotion: \tüòÑ Happy\n",
            "\n",
            "Input Text: \tI cannot swim across the lake\n",
            "Emotion: \tüòû Annoyed/Sad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Hz6nQXKv4V"
      },
      "source": [
        "# <font color=blue>This is an excellent model classification with obtained accuracy >90%, but this model being an emotion classifier, rather than a sentiment analyzer is not able to differentitate between Neutral sentiment and happy emotion, or even between a negative statement and a General opinion, as seen in the last 2 examples above, below the dashes.</font><br>\n",
        "# So as per current requirement, the Neutral/General type statement or sentences need to be filtered out before anything else. This is also the best option for the Psychometric Analysis, because the test expects a biased opinion or response from the user. If a neutral opton is given, not considering the question is the best possible option.\n",
        "# <font color=red>Another advantage of this model is that it is able to consider the punctuations in the sentence (which must be given after a white space as per the grammar/vocabulary trained in LSTM [RNN] in the above code) also affects the sentence to convey the emotions of the person. Combined with a face recognition and audio recognition frameworks to detect emotion, we can predict a person's set up of mind with about 100% accuracy‚ùó</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXbTsNYRNY71"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}